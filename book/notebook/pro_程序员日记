Mon Apr 13 12:10:10 CST 2015
今天一个每周定时运行的脚本出问题了, 检查过后发现是脚本里的一个字典把内存撑爆了。
这个字典按天记录从开服起到该天止有过某种行为的所有玩家uid。
这个脚本刚开始的时候，内存需求很小，第一个月只需要10M的内存。
很好，这样下来，一年也只需要120M的内存就行了。
可实际上，一年之后，3G的内存被这个字典吃爆了。
因为，这个字典是加速度增长的, 每天的历史总玩家数都比前一天的历史总玩家数多。
今天的数据量就是第一天数据量的100倍以上！
脚本就这样跪了。
如果我把每天的数据记录成与历史数据相比较的增量，就不会出现这个问题了。
如第一天记录所有相关玩家uid，第二天记录相对第一天的增量，第三条记录相对前两天的增量，第n天记录相对于前n-1天的增量。
就可以避免这个问题了。缺点就是在提取第n天的历史总用户时，要把前n天的数据进行汇总计算。
但在此种情形下，这种设计要比最终导致爆掉内存的设计优化得多。(因为它能运行不报错！速度还是要慢很多的 2015-06-27按)
这是我第一次真实遇到的数据结构的设计导致程序出错的情况。
引以为鉴。

另，python里，一个空字符的大小不是0，作为一个字符对象它的大小是37 byte。
整数1的大小是24字节，
一个空列表的大小是72字节
一个空集合的大小是232字节
一个空字典的大小是280字节
字符的大小增长是线性的，每增加一个ascii字符，大小增加1个byte.
列表的大小增长也是线性的, 每增加一个元素，大小增加8个byte,
但[{}]的大小并不是72+280, 而是72 + 8 = 80
其他数据结构大小的增长也有其特定的内在规律, 有兴趣可以进行进一步研究。


Mon Apr 13 16:13:29 CST 2015

将数据结构改了, 脚本运行时长是原来的5-6倍，而且计算是增量型的，不过增长速度还算温和。
头一次体会到时间换空间的含义！


Wed May  6 10:54:13 CST 2015

今日所得：
命名时如果有已有的较好理解的通用标准，使用通用标准，不要凭当时的感觉随性定个标准。
不然以后不仅坑别人，连自己都会被坑。locale_config命名方式和吴伟讨论有感。


Mon Jun  1 10:59:40 CST 2015
`rm rf /home/`, 今天我在越南服务器下座日志备份，我将home文件夹备份到 /home/admin/migration_backup文件夹下。
但是有一些小于1k的文件没有备份过来，我打算删除了migration_backup下面的home文件夹，再备份一个新的。
然后我使用了上面的命令。命令失败了，我定睛一看，吓出一身冷汗，在home一词前，我下意识加了个斜杠。如果执行成功的话
机器上的/home文件夹就要灰飞烟灭了。但我这儿犯了第二个错误，rf前少加了横杠。我太粗心大意了以至于自杀计划失败。。

从这事我反思得到下面几点：
1. 使用 rm -rf 时要想清楚（基本废话）
2. 备份文件要起一个不同的名字，在文件夹后加_backup, 在文件后面加.bk, 如此处我的备份文件夹应该叫`home_backup`
3. 使用rm -rf 时一定使用完整的绝对路径，如 `rm -rf /home/admin/migration_backup/home_backup`


Wed Jun  3 17:50:29 CST 2015
exchange_rate = yahoo_exchange_rate() or USD_EXCHANGE_RATE
这段代码，今天导致了好些玩家登不进服务器。它被放在一段for循环里, 多次执行。
yahoo_exchange_rate()会访问一个yahoo提供的api获得实时的人民币对美金汇率。
在测试服务器上，因为数据少，所以这个函数执行起来消耗还行。
但是在正式服务器上，放在for循环里的这个函数的执行，直接导致了进程的占用卡死。
而且每个地方访问yahoo api需要的时间不同啊, urlopen默认的报错时间貌似是10秒。
如果所在的服务器连不上yahoo的api.. oh my god.
这件事情的教训：
1. 在for循环里加东西一定要慎重（基本废话）
2. 调用远程服务器接口的时候一定考虑所需要花费的时间！！！
3. 能缓存的数据尽量缓存，本地总比联网快！


Mon Jun  8 18:21:20 CST 2015

今天在master服务器上复制，解压和压缩文件，特别卡。
然后回头一看玩家全掉线了。我的爷！
再不敢在master上随便操作了。CPU占用高的任务通通到admin上运行。
master等于同时有几百个用户在用啊。啊！


Thu Jun 11 15:08:25 CST 2015

没想到在管理机上的cp，压缩和解压缩操作，竟然导致了filesystem read-only! 惊了。
谨记服务器是豌豆公主，不是搓脚大汉。


Fri Jun 26 12:39:41 CST 2015
在做任何带有危险性的操作时，想想复原计划！
今天把自己精简的bashrc更新到远程服务器时，机器名字被替换掉了，而我没做原来配置的备份！糟了。。。


Sat Jun 27 10:42:24 CST 2015
昨天查错的时候，直接vim了一记，结果查过来查过去百思不得其解，今天早上tail -f, 发现发送http报错却不产生错误日志。yeh, 这是什么鬼咯，看nginx日志，有记录。顺着转发接口一路摸过去，嗨！supervisor里的进程15天前就停了, 崩溃！
下回测试再不vim看日志了，现点现tail -f


Wed Jul  8 17:33:53 CST 2015
用进化算法写了一个扫地机器人程序，每个机器人的基因组是一个有序列表，里面里有243条基因。
选取每一代的优胜者交配生成子代基因组时有三种策略: 
1. 固定选取父亲基因组的前50%，母亲基因组的后50%。
2. 切片选择父亲基因组的50%（可能是在基因组中间某个点选一段), 将剩下的基因片段替换为母亲的相应片段
3. 按50%的概率逐条随机选取父母的基因(制造一个0到1之间的随机数，该随机数大于0.5取父亲的该条基因，反之取母亲的该条基因), 进行243次选择后生成子代基因组

出乎我意料的是，第三种策略，机器人进化的速度最快，而第一种策略进化的速度最慢。
用比喻的语言说来：
上半身和爸爸完全一样，下半身完全和妈妈一样的机器人是最没出息的
脑袋像妈妈，躯干像爸爸，四肢像妈妈的机器人比第一种机器人强得多
而眉毛像妈妈，眼睛像爸爸，鼻子像妈妈，嘴唇像爸爸，牙齿像妈妈，舌头像爸爸, ... 的机器人，是最厉害的。

我想这可能和策略所允许的基因流动性有关。
第一种策略允许的基因流动性最小，除了偶尔的基因突变，它基本上是静止的。
而第二种策略通过变换基因片段的切割点，可以增强群体里不同基因的类型，但粒度还是过大。
而第三种策略，父母交配产生1000个子代，很可能没有任何两个的基因是完全相同的。

这种基因的快速流动，使得可能的子代基因组合大幅增加。而一个更丰富的基因组集合，比之数量贫乏的基因组组合，更容易产生表现更好的子代。
给你一个a, 你只能啊啊啊，给你a和b，你只能ab和ba, 但如果给你a到z，well, you see what already happened.

所以，结论是：丰富的resource更有利于进化？

最后附上三种策略进化一百代后各自选取的前10名的得分，三列得分项分别是：机器人得分，平均期望得分，理论最高得分
策略1:
(30, 235.0, 470)
(30, 235.0, 470)
(20, 235.0, 470)
(20, 235.0, 470)
(20, 235.0, 470)
(10, 235.0, 470)
(10, 235.0, 470)
(10, 235.0, 470)
(10, 235.0, 470)
(10, 235.0, 470)

策略2:
(60, 235.0, 470)
(60, 235.0, 470)
(50, 235.0, 470)
(50, 235.0, 470)
(50, 235.0, 470)
(50, 235.0, 470)
(50, 235.0, 470)
(50, 235.0, 470)
(50, 235.0, 470)
(50, 235.0, 470)

策略3:
(120, 235.0, 470)
(120, 235.0, 470)
(120, 235.0, 470)
(120, 235.0, 470)
(90, 235.0, 470)
(90, 235.0, 470)
(80, 235.0, 470)
(80, 235.0, 470)
(80, 235.0, 470)
(80, 235.0, 470)

Mon Aug  3 22:34:54 CST 2015

今天上线的巅峰王者的修复，是夹杂在外域的更新代码的。原来抱着侥幸心态想着应该没问题,

结果还是出事了，run_timer在调用外域中某个模块时因为typo导致的错误起不起来了。

啊，教训是，hotfix不要参杂其他代码，不要报侥幸心理！


2015-10-14 17:00

这几天在学C，感觉python里为程序员节省了的一大步骤是，不用考虑一个变量值计算后是什么类型的。变量不能计算时直接报错就好嘞。  
python把判别数据类型的脏活儿给你干了。
C语言里要用一个数值得先赋啊，python数值随便用啊。。


2015-10-16 16:24
javascript 倒省事，把所有的变量，叫做var。
还是python省事，var什么var? 不用var!

js 还真是学了蛮多c的，var a = function(arg1) { }
js代码比起python代码而言，多了一大堆{}........
python帮程序员省掉了一大堆不必要的符号，比如if后面的()，啊！
我草，javascript用的for循环语法和C一样。


2015-10-17 15:40
所以实际上python里的for语句帮我们完成了初始值设定，自增步骤和条件的判断


2015-10-19 12:47
在C语言里，`printf ("i");` 好使，我在想是不是C语言里，if和while都是函数！


2015-10-20 11:45
ipython 可以将shell和python命令混合编程！太屌了


2015-10-21 11:36
js里面，貌似字符，字典和列表虽然名义上type不一样，字符是'string', 后两个是'object', 但是貌似对内在属性都支持字典式调用属性值(python不支持）  
而且这三种数据类型都支持python式的模块属性调用  

> javascript里字典的key只能是字符，value可以是各种类型的数据

试看:
D = {'1': 'One!', 'b': "Big"}
D['1']
One!
D['b']
Big
D.b
Big
D.1
// Error!  1 is not valid for variable name, so error occurs here.

L = [3]
L[0]
3
L['length']
1
L.length
1

s = 'OK'
s[1]
'K'
s['length']
2
s.length
2


原来S = set()叫construct命名法，而 S2 = {1,2} 叫literal命名法

> 在python里，没有给空集合的literal命名方法，因为和空字典literal冲突了。


2015-10-31 15:53

原来C语言里用过的内存要自己去回收，而python让你不用操心这些。不过在python里，你实际上也可能遇到这个问题。  
那就是在global层面里用了大量的临时变量。  

表示忽然理解C语言里的函数是怎么回事了。其实它还是定义一个变量，只不过这个变量的类型是在经过一系列过程后产生的。  
其格式是：`变量类型  变量名（若干参数）{ 一系列过程;  return 之前声明的变量类型}`  


2015-11-06 10:27

再重复一下工程师金律（甚至是人生金律）：
   发现生活中有需要大量地重复做一件事时，想办法去自动化它，或至少做一些小工具优化它，降低它的消耗。
    不用担心你花在优化上的功夫会超过你重复做它的时间。你可以将优化成果分享给他人。这样优化的功效会更大。
    有的时候，你不必亲自去造轮子，别人早已找好轮子，你可以花点功夫去找这个轮子。一旦找到，也可以share他们出来。
    Share，你获得更多，听起来很weird，是不是，但这就是个反直觉的事实。
    Those who shares, will gain more power.


2015-11-10 17:18
所有的global语句执行时向上update的东西都依据他所处的环境而定。
今天用magic ball做的实验，貌似global语句会把东西update到 obj.__module__的scope里去，如果该scope存在


2015-11-16 16:59
觉得自己得多读代码了，当然不是BK或KL写的代码，而是python源码，site-package或者leetcode上的优秀代码之类的。
